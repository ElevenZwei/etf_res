# 整理方案
过去的代码只要不写说明就会变成乱七八糟的垃圾代码。
然后自己也不知道怎么整理怎么清理。
所以说一个可以长期持续的生存方案需要很多部分。
比如说输入部分的阶段流程化处理，
还有输出部分的流程化处理，不能全都混在一个文件夹里面了。

## 运行方法
`python -m backtest.nautilus.backtest_xxx <args>`  
运行之后会产生三个 csv 文件，输出在 `backtest/data/output` 位置。  
分别是 `account / order / pos` 三个 csv 文件。  

对于运行之后产品的后期处理，现在有 log 处理和 csv 处理两个路线。  
首推 csv 处理的路线，在有了三个 csv 文件之后运行两个脚本。  
`python -m backtest.nautilus.afx.afx_order_df -f <order.csv>`  
`python -m backtest.nautilus.afx.afx_order_2_worth -s <suffix in opt_order_{suffix}_t.csv>`  
第一个脚本整理 nautilus 回测框架输出的 order csv 文件内容。
第二个脚本读取标的价格和订单记录合成账户的净值变化。  

## 策略说明
这套系统当时做出来的时候就非常赶时间，所以很多地方都是补丁和奇怪的 IF 。
代码里面的 size_mode 同时肩负了只做多，只做空，每日平仓还是不平仓的功能。  

strategy_buy, strategy_sell, strategy_syn 都是读取外界输入的信号，然后交易期权的回测代码。  
外界信号用一个 -1 ~ 1 之间的数字表示当前持仓的方向和比例。  

strategy_buy 现在的逻辑是按照持仓比例购买对应方向的期权，最大购买量在从零开仓的时候判定。一旦拥有了持仓，当方向不变的时候，只是调整持仓数字，不会更换合约。在方向变换的时候会清空之前的仓位重新开仓。  
这样的机制让我怀疑在赚钱的时候它占用的资金可能不小，尤其是一开始没开多少，然后后面陆续加仓的情景里面，因为最大持仓量是在一开始开仓的时候判定的。所以说后续占用资金可能会超出预算。如果在这个状态下一旦开始走向亏损，亏损值也会超出一开始的预算。  
一个更加好的做法是定期刷新它的最大持仓量，我们需要在 Underlying 价格移动 1% 以上，或者每隔十分钟计算新的最大持仓量数字，这样可能风险更加可控一些。

## 回测系统和现有数据库的迁移
现在的 backtest 系统已经有一点乱套了。因为它的结果我已经有一些分不清哪个是什么参数和代码产生的了。  
1. buy_cpr_d5   这个后缀表示 CPR 信号买权 delta 0.5 的回测。  
2. buy_cpr_d5_rmax1p 这个后缀表示再加上 full size refresh 逻辑的回测。  
3. buy_cpr_d5_sa 这个是取消了相同信号跳过捷径的代码，应该和 1 的结果一致。  
4. buy_cpr_d5_rmax1p_sa 这个是在每次 full size refresh 的同时都会重新调整仓位，这个和 rf 会产生差异，从这点可以分析调整最大持仓量的稳定性问题。但是从结论上看，只会衰减收益，却不能增加稳定性。还是一开始的 buy_cpr_d5 最安全。  
5. buy_cpr_d5_l5   这个后缀表示 CPR 信号买权 delta 0.5 的回测，当信号小于 0.5 的时候当作 0。  
6. buy_cpr_d5_l3   这个后缀表示 CPR 信号买权 delta 0.5 的回测，当信号小于 0.3 的时候当作 0。  
7. buy_cpr_d5_l3_h7   这个后缀表示 CPR 信号买权 delta 0.5 的回测，当信号小于 0.3 的时候当作 0，当信号大于 0.7 的时候当作 1 。  

我感觉这些东西的影响都不大，除非我们可以设计出更多种不同的 Roll 方式，让它挑选出来的参数更加的多样化。

我需要一个更加完善灵活的结构，它应该可以和数据库连接起来。  

## 输入数据说明
2024 年数据的主要文件是 tl_greeks_159915_all_fixed.csv 文件。  
这个文件里面包含了 2024 年的创业板期权数据。
文件名结尾有 fixed 表示它的价格是 close price 。
否则通联的原始数据价格是 open price 。  

2025 年数据输入的文件是 `input/opt_159915_2025_*.csv`  
计算 Greeks 的脚本是 `159915_2025.py` 。  
我们现在应该已经有到 0709 为止的数据，那么我们用合成地方式处理一下。  
0709 到 0815 这段先放一下。


输入解析的逻辑代码在 data_types.py 里面，这里面有它会去解读的数据列。

# 2025-09-03 陈诚信号的回测  
这个核心问题是它是 159949 上的交易信号，我不知道这个东西的期权我有没有。  
这个是创业板 50 ETF。之前没有做过。  
不过看起来它的走势和 159915 非常相近，所以我先用 159915 的期权来测试一下交易的效果。  


# 2025-08-25 CPR 系统信号的实盘交易  
这个方面最大的需要是期权交易系统的进一步模块化，根据输入的信号得到不同的交易分支策略的仓位。  
这些仓位构成持仓的结构。所以是 C++ 的代码里面进一步合成模块的方法。  


# 2025-08-19 CPR 系统的信号回测
我们主要考虑追加数据过程里面的自动处理方法。  
这有两个方面需要设计，一个是怎么自动收集计算所有的 Greeks 。  
另一个方面是搞一个新的表格能够直接读取数据，不要总是 CSV 中转了。  



# 2025-05-21 郑心棠的信号回测

## 需求和设计
James 目前的想法是，在她的信号和我们的固定值信号出现重叠的时候进行交易。

我打算在外合成信号，然后在 nautilus 里面做几个根据信号产生期权持仓的回测代码。
这样这个回测代码之后是各种信号都可以通用的，对减轻我的负担大有好处。

考虑到郑心棠的信号有仓位大小，所以我用 4000 固定阈值在郑心棠的信号上做一个 mask 。  
4000 固定阈值的信号是 oi_signal_159915_act_changes.csv 。  
导入这个 csv 之后，用 pandas join 一下两个 df ，然后 ffill ，再做一下 mask。  
这样就得到了重叠的信号，然后再用这个重叠的信号，输入 nautilus 去做回测。

所以说，我们如果想要做固定阈值的信号回测，需要读取的是  
`oi_signal_159915_act_changes.csv`  
如果需要做 zxt pcr 原始信号的回测，我们需要读取  
`zxt_pcr_action_changes.csv`  
如果需要做综合信号的回测，我们需要读取的是  
`zxt_mask_action_changes.csv`

现在信号文件我都得到了，下一步是编写读取标的价格和信号的 Nautilus 策略。
价格数据在 `input/options_data.csv` 里面，  
这个文件里面有 2024 年 1 月 - 10 月 23 日的 159915 的所有期权价格数据。

按照我之前的买权策略 `strategy_buy.py` 的要求，
这个策略文件需要把 Signal 和 Spot 行情组合在一起。

